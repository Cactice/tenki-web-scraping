{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "weather_url = 'http://www.weather-eye.com/weatherchart/'\n",
    "r  = requests.get(weather_url)\n",
    "data = r.content\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "ken = {} # ken means prefecture in Japanese\n",
    "\n",
    "for each in soup.find_all('a'):\n",
    "    ken_id = re.search('_(\\d{5}).',each.get('href')).group(1)\n",
    "    ken_name = each.get_text()\n",
    "    ken[ken_name] = ken_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.weather-eye.com/weatherchart/src/1512_47827.htm'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# typical target url => http://www.weather-eye.com/weatherchart/src/1510_47682.htm\n",
    "\n",
    "target_ken_name = '鹿児島'\n",
    "target_ken_id = ken[target_ken_name]\n",
    "target_date = '151213' #yymmdd\n",
    "target_month = re.search('^\\d{4}', target_date).group(0)\n",
    "url_prefix = 'http://www.weather-eye.com/weatherchart/src/'\n",
    "url_suffix = '.htm'\n",
    "full_url = url_prefix +target_month+'_' + target_ken_id +url_suffix\n",
    "full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r  = requests.get(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['快晴', '快晴', '19.4', '9.3'], 2: ['くもり', '雨', '20.4', '11.3'], 3: ['はれ', '雨', '16.3', '11.8'], 4: ['雨', 'はれ', '14.9', '9.4'], 5: ['はれ', 'くもり', '15.2', '9.6'], 6: ['雨', '雨', '11.6', '8.9'], 7: ['はれ', 'はれ', '18.1', '10.7'], 8: ['快晴', '快晴', '18.9', '7.8'], 9: ['はれ', 'はれ', '19.3', '8'], 10: ['雨', '雨', '21.3', '16.3'], 11: ['雨', 'はれ', '20.3', '14.1'], 12: ['くもり', 'はれ', '16.4', '12.7'], 13: ['はれ', '快晴', '18.3', '11.5'], 14: ['くもり', 'はれ', '17.4', '11.3'], 15: ['雨', '雨', '18.7', '11.6'], 16: ['くもり', '雨', '13.4', '8.7'], 17: ['雨', '雨', '9.1', '5.1'], 18: ['快晴', '快晴', '11.1', '1.8'], 19: ['快晴', '快晴', '13.2', '4.2'], 20: ['はれ', 'くもり', '17.2', '6.4'], 21: ['雨', 'はれ', '21', '11.2'], 22: ['はれ', 'はれ', '19.9', '11.2'], 23: ['雨', '雨', '19.4', '14.4'], 24: ['くもり', '雨', '18.2', '13.2'], 25: ['快晴', '快晴', '15.8', '8.2'], 26: ['快晴', 'くもり', '14.8', '6.8'], 27: ['くもり', 'くもり', '14.7', '9.5'], 28: ['快晴', 'はれ', '14', '6.2'], 29: ['はれ', 'はれ', '12.2', '4.9'], 30: ['くもり', '快晴', '14.6', '3.5'], 31: ['はれ', '雨', '12.8', '5.6']}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "data = r.content\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "body = soup.find('body')\n",
    "table = body.findAll('table')[6]\n",
    "tr = table.findAll('tr')\n",
    "monthObj = {}\n",
    "day = 0\n",
    "day2 = 0\n",
    "del tr[0]\n",
    "for index, each_tr in enumerate(tr):\n",
    "    if index % 3 == 0:\n",
    "        for b in each_tr.findAll('b'):\n",
    "            monthObj[int(b.get_text())] = []\n",
    "    if index % 3 == 1:\n",
    "        for font in each_tr.findAll('font'):\n",
    "            day += 0.5\n",
    "            date = math.ceil(float(day))\n",
    "            monthObj[date].append(font.get_text())\n",
    "    if index % 3 == 2:\n",
    "        for font in each_tr.findAll('font'):\n",
    "            day2 += 0.5\n",
    "            date = math.ceil(float(day2))\n",
    "            monthObj[date].append(font.get_text())\n",
    "print(monthObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
